---
layout: single
title: NEURO-DRAM- A 3D Recurrent Visual Attention Model For Interpretable Neuroimaging Classification

permalink: /neurodram/
author_profile: true
# toc: true
# classes: wide
# header:
#     image: /assets/images/hgms_3.png
#     # overlay_filter: 0.5
#     caption: "Photo credit: [**IEEE**](https://arxiv.org/pdf/1910.04721.pdf)"

---
## Super Short Introduction
* [Paper Link](https://arxiv.org/pdf/1910.04721.pdf)
It works on 3D MRI data of human brain primarily for prediction of Alzheimer disease. Novelty of the paper is more generalizability, more interpretebility and faster training time, all due to its novel architectural design. A RL agent is trained to find small 3D volumes of interest from which feature are generated which are subsequently assimilated with LSTM. Additionally, it naturally supports other forms of non-imaging input information by incorporating them as LSTM's initial state.

## Brief Description of Main Ideas
<figure>
    <a href="../assets/images/james_cole_1.png"><img src="../assets/images/james_cole_1.png"></a>
    <figcaption>Proposed Architecture (Credits: https://arxiv.org/pdf/1910.04721.pdf).</figcaption>
</figure>

### Glimpse Network
* Input: Location vector $$l_t$$ generated by Location Network and a glimpse $$x_t$$ (a small 3D volume) around the location.
* Output: A vector $$g_t$$ representing what has been seen and where it has been seen.
* Internals: $$x_t$$ is passed through a 3D CNN to yield $$g_{x,t}$$. $$l_t$$ is passed through a fully connected layer to yield
>$$g_{l,t}$$. $$g_t = g_{x,t}\bigodot g_{l,t}$$

### Recurrent Network
* Input($$(t +1)^{th}$$ step): $$g_t$$, the output of glimpse network. It also takes as input $$r_0$$ in the first step.
* Output($$(t +1)^{th}$$ step): $$t^{t+1}$$ which has the assimilated information from looking at $$\{x_0,..x_t\}$$
* Interlals: This network assimilates information from all seen glimpses till that point in time.

### Other sub-networks
* Location network is a single fully connected network giving output a 3D vector $$\mu_t$$. The location $$l_{t+1}$$ is sampled from a gaussian network with $$\mu_t$$ as mean. This randomness improves generalization.
* Non-imaging context network takes as input non image based input and generates a representation which gets fed to the Recurrent network.
* Classification network is a single layer fully connected NN with sigmoid activation. Output from the recurrent network is fed to this network as input for predicting the probablity of Alzheimer disease. By not using the output of the Non-imaging context netowrk, it keeps MRI data as the primary source of knowledge with other data more like a 'supplimentary info'.

### RL Agent Configuration
* Input($$(t +1)^{th}$$ step): a new glimpse $$x_t$$ and a scalar reward $$r_t$$. $$r_t$$ is set to 1 for all timesteps if the classification was done correctly.

### Training
Since they have the classification labels , Classification and Glimpse network parameters (can be and therefore) are trained in a supervised fashion. Sampling the location introduces a discontinuity and so the initials components of Location and Context network are trained via reinforcement learning.

